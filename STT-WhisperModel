#this code is for speech recognition with the help of Whisper model and tKinter
import tkinter as tk
from PIL import ImageTk, Image
import speech_recognition as sr
import whisper
import os
import queue
import torch
import numpy as np
import warnings
import threading

warnings.filterwarnings('ignore')

# Initialize global variables
predicted_text = ""
audio_queue = queue.Queue()
result_queue = queue.Queue()
running = False

def start_listening():
    global running
    running = True
    start_button.config(state=tk.DISABLED)
    stop_button.config(state=tk.NORMAL)
    threading.Thread(target=generate_response).start()

def stop_listening():
    global running
    running = False
    start_button.config(state=tk.NORMAL)
    stop_button.config(state=tk.DISABLED)

def generate_response():
    audio_model = whisper.load_model("small.pt")
    english = False
    lang = "hi"
    verbose = False
    energy = 300
    pause = 0.8
    dynamic_energy = False
    save_file = False

    r = sr.Recognizer()
    r.energy_threshold = energy
    r.pause_threshold = pause
    r.dynamic_energy_threshold = dynamic_energy

    with sr.Microphone(sample_rate=16000) as source:
        output_text.insert(tk.END, "Say something!...\n", "heading")
        while running:
            audio = r.listen(source)
            torch_audio = torch.from_numpy(np.frombuffer(audio.get_raw_data(), np.int16).flatten().astype(np.float32) / 32768.0)
            audio_data = torch_audio

            audio_queue.put_nowait(audio_data)

            audio_data = audio_queue.get()
            if english:
                result = audio_model.transcribe("nnnn", audio_data, lang)
            else:
                result = audio_model.transcribe(audio_data)

            if not verbose:
                predicted_text = result["text"]
                result_queue.put_nowait(predicted_text)

                if predicted_text.lower() in ['exit', 'exit.'] or 'exit' in predicted_text.lower() or 'exit.' in predicted_text.lower():
                    print("dictation stopped")
                    stop_listening()
            else:
                result_queue.put_nowait(result)

            if save_file:
                os.remove(audio_data)
                print(result_queue.get())

            # Update the output textbox with the recognized text
            output_text.delete(1.0, tk.END)
            output_text.insert(tk.END, predicted_text)

# Create the GUI
root = tk.Tk()
root.title("Whisper")
root.geometry("800x600")  
root.resizable(True, True)

# Load background image
image = Image.open("back.jpg")
background_image = ImageTk.PhotoImage(image)
background_label = tk.Label(root, image=background_image)
background_label.place(x=0, y=0, relwidth=1, relheight=1)

# Create start button
start_button_img = ImageTk.PhotoImage(file=r"MIC1.jpg")
start_button = tk.Button(root, image=start_button_img, command=start_listening,  bd=0, relief=tk.GROOVE, bg="#FFFFFF")
start_button.place(x=120, y=260, width=50, height=50)

# Create stop button
stop_button_img = ImageTk.PhotoImage(file=r"stop1.jpg")
stop_button = tk.Button(root,  image=stop_button_img, command=stop_listening, state=tk.DISABLED,  bd=1, relief=tk.SOLID, bg="#E6E6E6")
stop_button.place(x=110, y=360, width=80, height=40)

speech_label = tk.Label(root, text="WHISPER", font=("Calibri", 12), bg="#FFFFFF")
speech_label.place(x=110, y=500)

# Output textbox
output_text = tk.Text(root, height=20, width=50)
output_text.place(x=280, y=20, width=root.winfo_width() - 310, height=root.winfo_height() - 40)
output_text.config(font=("Arial", 12), wrap=tk.WORD, relief=tk.SOLID, bd=1)

output_text.tag_configure("heading", font=("Courier", 15, "bold"), foreground="#d37e7e")
output_text.tag_configure("normal", font=("Calibri", 12), foreground="black")
output_text.tag_configure("error", font=("Arial", 12, "bold"), foreground="red")

def update_window(event):
    output_text.place(x=280, y=20, width=root.winfo_width() - 310, height=root.winfo_height() - 40)

root.bind("<Configure>", update_window)

# Run the GUI event loop
root.mainloop()
